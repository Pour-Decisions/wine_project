{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9073d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "\n",
    "import sklearn.preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.feature_selection import f_regression, SelectKBest, RFE \n",
    "from sklearn.linear_model import LinearRegression, LassoLars, TweedieRegressor\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt \n",
    "\n",
    "def combined_df(df, f1, f2):\n",
    "    '''\n",
    "    This function calls another function in explore.py \n",
    "    and merges a column to the original dataset\n",
    "    '''\n",
    "    \n",
    "    X = clustering(df, f1, f2)\n",
    "    \n",
    "    scaled_clusters = X['scaled_clusters']\n",
    "    df = pd.merge(df, scaled_clusters, left_index=True, right_index=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def cluster_relplot(df, f1, f2):\n",
    "    '''\n",
    "    this functions creates a relplot of the clusters\n",
    "    '''\n",
    "    \n",
    "    sns.set(style = \"whitegrid\")\n",
    "    \n",
    "    X = clustering(df, f1, f2)\n",
    "    \n",
    "    sns.relplot(data = X, x = f1, y = f2, hue = 'scaled_clusters')\n",
    "    \n",
    "    plt.title('Clusters')\n",
    "    \n",
    "    return plt.show()\n",
    "\n",
    "\n",
    "\n",
    "def clustering(train, f1, f2):\n",
    "    '''\n",
    "    clustering fits and predicts Kmeans clustering to the input featues of the\n",
    "    dataset\n",
    "    '''\n",
    "    # set random seed\n",
    "    seed = 828\n",
    "    # define 'X'\n",
    "    X = train[[f1, f2]]\n",
    "    # fit the thing\n",
    "    kmeans = KMeans(n_clusters = 3, random_state= seed)\n",
    "    kmeans.fit(X)\n",
    "    kmeans.predict(X)\n",
    "    # scale features\n",
    "    mm_scaler = MinMaxScaler()\n",
    "    X[[f1, f2]] = mm_scaler.fit_transform(X[[f1, f2]])\n",
    "    # predict\n",
    "    kmeans_scale = KMeans(n_clusters = 3, random_state = 828)\n",
    "    kmeans_scale.fit(X[[f1, f2]])\n",
    "    kmeans_scale.predict(X[[f1, f2]])\n",
    "    # add predictions to a new column\n",
    "    X['scaled_clusters'] = kmeans_scale.predict(X[[f1, f2]])\n",
    "    \n",
    "    return X  \n",
    "\n",
    "def best_cluster(train, f1, f2):\n",
    "    '''\n",
    "    best_cluster takes in the data set, and the two feautures to cluster,\n",
    "    then makes a graph to show the most optimal cluster number.\n",
    "    '''\n",
    "    # define 'X'\n",
    "    X = clustering(df, f1, f2)\n",
    "    # empty list\n",
    "    inertia = []\n",
    "    seed = 828 \n",
    "    # for loop to test different number of clusters\n",
    "    for n in range(1,11):\n",
    "\n",
    "        kmeans = KMeans(n_clusters = n, random_state = seed)\n",
    "\n",
    "        kmeans.fit(X[[f1, f2]])\n",
    "\n",
    "        inertia.append(kmeans.inertia_)\n",
    "        \n",
    "    # append reults to new df    \n",
    "    results_df = pd.DataFrame({'n_clusters': list(range(1,11)),\n",
    "                               'inertia': inertia})   \n",
    "    # plot the reults\n",
    "    sns.set_style(\"whitegrid\")\n",
    "    sns.relplot(data = results_df, x='n_clusters', y = 'inertia', kind = 'line')\n",
    "    plt.xticks(np.arange(0, 11, step=1))\n",
    "    point = (3, 110) # specify the x and y values of the point to annotate\n",
    "    plt.annotate(\"optimal cluster\", xy=point, xytext=(3.2, 140), \n",
    "                 arrowprops=dict(facecolor='black', shrink=0.05))\n",
    "    # title\n",
    "    plt.title('Clusters Versus Inertia')\n",
    "    \n",
    "    return plt.show()\n",
    "    \n",
    "    return plt.show()\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "def find_best_features(df, k_min, k_max):\n",
    "    '''\n",
    "    This function takes in a dataframe,  a minimum number \n",
    "    of clusters (k_min), and a maximum number \n",
    "    of clusters (k_max). It returns a list of the best features \n",
    "    to use for clustering based on the Silhouette score.\n",
    "    '''\n",
    "    # Remove the target column from the dataframe\n",
    "    X = df.drop(['quality', 'color'], axis=1)\n",
    "    \n",
    "    # Create an empty list to store the best features\n",
    "    best_features = []\n",
    "    \n",
    "    # Loop through the range of k values\n",
    "    for k in range(k_min, k_max+1):\n",
    "        # Fit a KMeans clustering model\n",
    "        kmeans = KMeans(n_clusters=k, random_state=828).fit(X)\n",
    "        \n",
    "        # Calculate the Silhouette score for the clustering\n",
    "        score = silhouette_score(X, kmeans.labels_)\n",
    "        \n",
    "        # If this is the first iteration, add all features to the best_features list\n",
    "        if k == k_min:\n",
    "            best_features = list(X.columns)\n",
    "        else:\n",
    "            # For each subsequent iteration, compare the Silhouette score to the previous iteration\n",
    "            # If the score has improved, update the best_features list with the current set of features\n",
    "            if score > prev_score:\n",
    "                best_features = list(X.columns)\n",
    "        \n",
    "        # Set the previous score to the current score for the next iteration\n",
    "        prev_score = score\n",
    "    \n",
    "    # Return the list of best features\n",
    "    return best_features\n",
    "\n",
    "\n",
    "\n",
    "def scale_data(train, validate, test, return_scaler=False):\n",
    "    '''\n",
    "    Scales the 3 data splits. \n",
    "    Takes in train, validate, and test data splits and returns their scaled counterparts.\n",
    "    If return_scalar is True, the scaler object will be returned as well\n",
    "    '''\n",
    "    columns_scale = train.iloc[:, :11]\n",
    "    columns_to_scale = columns_scale.columns\n",
    "    \n",
    "    # make copies of our original data so we dont gronk up anything\n",
    "    train_scaled = train.copy()\n",
    "    validate_scaled = validate.copy()\n",
    "    test_scaled = test.copy()\n",
    "    #     make the thing\n",
    "    mms = sklearn.preprocessing.MinMaxScaler()\n",
    "    #     fit the thing\n",
    "    mms.fit(train[columns_to_scale])\n",
    "    # applying the scaler:\n",
    "    train_scaled[columns_to_scale] = pd.DataFrame(mms.transform(train[columns_to_scale]),\n",
    "                                                  columns=train[columns_to_scale].columns.values).set_index([train.index.values])\n",
    "                                                  \n",
    "    validate_scaled[columns_to_scale] = pd.DataFrame(mms.transform(validate[columns_to_scale]), \n",
    "                                                     columns=validate[columns_to_scale].columns.values).set_index([validate.index.values])\n",
    "    \n",
    "    test_scaled[columns_to_scale] = pd.DataFrame(mms.transform(test[columns_to_scale]),\n",
    "                                                 columns=test[columns_to_scale].columns.values).set_index([test.index.values])\n",
    "    \n",
    "    if return_scaler:\n",
    "        return scaler, train_scaled, validate_scaled, test_scaled\n",
    "    else:\n",
    "        return train_scaled, validate_scaled, test_scaled\n",
    "\n",
    "\n",
    "def splitting_subsets(train, train_scaled, validate_scaled, test_scaled):\n",
    "    '''\n",
    "    This function splits our train, validate, and test scaled datasets into X/y train,\n",
    "    validate, and test subsets\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    X_train = train_scaled.drop(columns = ['quality'])\n",
    "    X_train = pd.get_dummies(X_train, columns = ['color', 'scaled_clusters'])\n",
    "    y_train = train_scaled['quality']\n",
    "\n",
    "\n",
    "    X_validate = validate_scaled.drop(columns = ['quality'])\n",
    "    X_validate = pd.get_dummies(X_validate, columns = ['color', 'scaled_clusters'])\n",
    "    y_validate = validate_scaled['quality']\n",
    "\n",
    "\n",
    "    X_test = test_scaled.drop(columns = ['quality'])\n",
    "    X_test = pd.get_dummies(X_test, columns = ['color', 'scaled_clusters'])\n",
    "    y_test = test_scaled['quality']\n",
    "\n",
    "    return X_train, y_train, X_validate, y_validate, X_test, y_test\n",
    "\n",
    "\n",
    "def get_baseline(y_train):\n",
    "    '''\n",
    "    This function takes in y_train, then calculates the baseline RMSE\n",
    "    '''\n",
    "    \n",
    "    preds_df = pd.DataFrame({'actual': y_train})\n",
    "    \n",
    "    preds_df['baseline'] = y_train.mean()\n",
    "    \n",
    "    baseline_rmse = sqrt(mean_squared_error(preds_df.actual, preds_df.baseline))\n",
    "\n",
    "    return baseline_rmse\n",
    "\n",
    "\n",
    "def linear_model(X_train, y_train):\n",
    "    '''\n",
    "    This function makes a linear regression model, fits, and predicts the output values.\n",
    "    Giving us a dataframe of predicted linear and actual values\n",
    "    '''\n",
    "    \n",
    "    lm = LinearRegression()\n",
    "\n",
    "    lm.fit(X_train, y_train)\n",
    "    \n",
    "    lm_preds = lm.predict(X_train)\n",
    "    \n",
    "    preds_df = pd.DataFrame({'actual': y_train,'lm_preds': lm_preds})\n",
    "    \n",
    "    lm_rmse = sqrt(mean_squared_error(preds_df['lm_preds'], preds_df['actual']))\n",
    "    \n",
    "    df = pd.DataFrame({'model': 'linear', 'linear_rmse': lm_rmse},index=['0']) \n",
    "                      \n",
    "    return df\n",
    "\n",
    "\n",
    "def lasso_lars(X_train, y_train):\n",
    "    \n",
    "    '''\n",
    "        This function is used to run a for loop on lasso lars. We will use the best preforming model,\n",
    "        and use it on the validate datasets.\n",
    "    '''\n",
    "    \n",
    "    metrics = []\n",
    "\n",
    "    for i in np.arange(0.05, 1, .05):\n",
    "    \n",
    "        lasso = LassoLars(alpha = i )\n",
    "    \n",
    "        lasso.fit(X_train, y_train)\n",
    "    \n",
    "        lasso_preds = lasso.predict(X_train)\n",
    "        \n",
    "        preds_df = pd.DataFrame({'actual': y_train})\n",
    "    \n",
    "        preds_df['lasso_preds'] = lasso_preds\n",
    "\n",
    "        lasso_rmse = sqrt(mean_squared_error(preds_df['actual'], preds_df['lasso_preds']))\n",
    "    \n",
    "        output = {\n",
    "                'alpha': i,\n",
    "                'lasso_rmse': lasso_rmse\n",
    "                 }\n",
    "    \n",
    "        metrics.append(output)\n",
    "\n",
    "    df = pd.DataFrame(metrics)    \n",
    "    return df.sort_values('lasso_rmse')\n",
    "\n",
    "\n",
    "def tweedie_models(X_train, y_train):\n",
    "    \n",
    "    '''\n",
    "    This function is used to run a for loop on tweedie model. We will use the best preforming model,\n",
    "    and use it on the validate datasets.\n",
    "    '''\n",
    "    \n",
    "    metrics = []\n",
    "\n",
    "    for i in range(0, 4, 1):\n",
    "    \n",
    "        tweedie = TweedieRegressor(power = i)\n",
    "    \n",
    "        tweedie.fit(X_train, y_train)\n",
    "    \n",
    "        tweedie_preds = tweedie.predict(X_train)\n",
    "        \n",
    "        preds_df = pd.DataFrame({'actual': y_train})\n",
    "    \n",
    "        preds_df['tweedie_preds'] = tweedie_preds\n",
    "    \n",
    "        tweedie_rmse = sqrt(mean_squared_error(preds_df.actual, preds_df.tweedie_preds))\n",
    "    \n",
    "        output = {\n",
    "                'power': i,\n",
    "                'tweedie_rmse': tweedie_rmse\n",
    "                 }\n",
    "    \n",
    "        metrics.append(output)\n",
    "\n",
    "    df = pd.DataFrame(metrics)    \n",
    "    return df.sort_values('tweedie_rmse') \n",
    "\n",
    "\n",
    "def linear_poly(X_train, y_train):\n",
    "    \n",
    "    '''\n",
    "        This function is used to run a for loop on liner poly. We will use the best preforming model,\n",
    "        and use it on the validate datasets.\n",
    "    '''\n",
    "    \n",
    "    metrics = []\n",
    "\n",
    "    for i in range(2,4):\n",
    "\n",
    "        pf = PolynomialFeatures(degree = i)\n",
    "\n",
    "        pf.fit(X_train, y_train)\n",
    "\n",
    "        X_polynomial = pf.transform(X_train)\n",
    "\n",
    "        lm2 = LinearRegression()\n",
    "\n",
    "        lm2.fit(X_polynomial, y_train)\n",
    "        \n",
    "        preds_df = pd.DataFrame({'actual': y_train})\n",
    "\n",
    "        preds_df['poly_preds'] = lm2.predict(X_polynomial)\n",
    "\n",
    "        poly_rmse = sqrt(mean_squared_error(preds_df['actual'], preds_df['poly_preds']))\n",
    "\n",
    "        output = {\n",
    "                'degree': i,\n",
    "                'poly_rmse': poly_rmse\n",
    "                 }\n",
    "\n",
    "        metrics.append(output)\n",
    "\n",
    "    df = pd.DataFrame(metrics)    \n",
    "    return df.sort_values('poly_rmse') \n",
    "\n",
    "\n",
    "def validate_models(X_train, y_train, X_validate, y_validate):\n",
    "    '''\n",
    "    This model is used to test our models on the validate datasets and then return the results. \n",
    "    These results will then be used to find our best model.\n",
    "    '''\n",
    "       \n",
    "    lm = LinearRegression()\n",
    "\n",
    "    lm.fit(X_train, y_train)\n",
    "    \n",
    "    lm_val = lm.predict(X_validate)\n",
    "    \n",
    "    val_preds_df = pd.DataFrame({'actual_val': y_validate})\n",
    "    \n",
    "    val_preds_df['lm_preds'] = lm_val\n",
    "\n",
    "    lm_rmse_val = sqrt(mean_squared_error(val_preds_df['actual_val'], val_preds_df['lm_preds']))\n",
    "\n",
    "    #tweedie model\n",
    "    \n",
    "    tweedie = TweedieRegressor(power = 1)\n",
    "    \n",
    "    tweedie.fit(X_train, y_train)\n",
    "    \n",
    "    tweedie_val = tweedie.predict(X_validate)\n",
    "    \n",
    "    val_preds_df['tweedie_preds'] = tweedie_val\n",
    "    \n",
    "    tweedie_rmse_val = sqrt(mean_squared_error(val_preds_df.actual_val, val_preds_df.tweedie_preds))\n",
    "    \n",
    "    #polynomial model\n",
    "    \n",
    "    pf = PolynomialFeatures(degree = 2)\n",
    "    \n",
    "    pf.fit(X_train, y_train)\n",
    "    \n",
    "    X_train = pf.transform(X_train)\n",
    "    X_validate = pf.transform(X_validate)\n",
    "    \n",
    "    lm2 = LinearRegression()\n",
    "    \n",
    "    lm2.fit(X_train, y_train)\n",
    "    \n",
    "    val_preds_df['poly_vals'] = lm2.predict(X_validate)\n",
    "    \n",
    "    poly_validate_rmse = sqrt(mean_squared_error(val_preds_df.actual_val, val_preds_df['poly_vals']))\n",
    "\n",
    "    #lasso_lars model\n",
    "    \n",
    "    lasso = LassoLars(alpha = .05 )\n",
    "    \n",
    "    lasso.fit(X_train, y_train)\n",
    "    \n",
    "    lasso_val = lasso.predict(X_validate)\n",
    "    \n",
    "    val_preds_df['lasso_preds'] = lasso_val\n",
    "\n",
    "    lasso_rmse_val = sqrt(mean_squared_error(val_preds_df.actual_val, val_preds_df['lasso_preds']))\n",
    "    \n",
    "    \n",
    "    return lm_rmse_val, tweedie_rmse_val, lasso_rmse_val, poly_validate_rmse\n",
    "\n",
    "\n",
    "def best_models(X_train, y_train, X_validate, y_validate):\n",
    "    \n",
    "    '''\n",
    "    This function uses the train and validate datasets and returns the results of the best preforming model \n",
    "    for each algorithm. The results are returned as a dataframe.\n",
    "    '''\n",
    "    \n",
    "    lm_rmse = linear_model(X_train, y_train).iloc[0,1]\n",
    "    \n",
    "    lasso_rmse = lasso_lars(X_train, y_train).iloc[0,1]\n",
    "    \n",
    "    tweedie_rmse = tweedie_models(X_train, y_train).iloc[0,1]\n",
    "        \n",
    "    poly_rmse = linear_poly(X_train, y_train).iloc[1,1]\n",
    "    \n",
    "    baseline_rmse = get_baseline(y_train)\n",
    "    \n",
    "    lm_rmse_val, tweedie_rmse_val, lasso_rmse_val, poly_validate_rmse = validate_models(X_train, y_train, X_validate, y_validate)\n",
    "    \n",
    "    df = pd.DataFrame({'model': ['linear', 'tweedie', 'lasso_lars','linear_poly', 'baseline'],\n",
    "                      'train_rmse': [lm_rmse, tweedie_rmse, lasso_rmse, poly_rmse,  baseline_rmse],\n",
    "                      'validate_rmse': [lm_rmse_val, tweedie_rmse_val, lasso_rmse_val, poly_validate_rmse, baseline_rmse]})\n",
    "    \n",
    "    df['difference'] = df['train_rmse'] - df['validate_rmse']\n",
    "    \n",
    "    return df.sort_values('difference').reset_index().drop(columns = ('index'))\n",
    "\n",
    "\n",
    "\n",
    "def test_model(X_train, y_train, X_test, y_test):\n",
    "    '''\n",
    "    This function is used to test our best model and use it \n",
    "    on the test datasets to get our final results.\n",
    "    '''\n",
    "    \n",
    "    # Step 1: Create a PolynomialFeatures object with degree=2\n",
    "    pf = PolynomialFeatures(degree=2)\n",
    "    \n",
    "    # Step 2: Fit the PolynomialFeatures object to the training data\n",
    "    pf.fit(X_train)\n",
    "    \n",
    "    # Step 3: Transform the training and test data using the fitted PolynomialFeatures object\n",
    "    X_train_poly = pf.transform(X_train)\n",
    "    X_test_poly = pf.transform(X_test)\n",
    "    \n",
    "    # Step 4: Create a LinearRegression object and fit it to the transformed training data\n",
    "    lm2 = LinearRegression()\n",
    "    lm2.fit(X_train_poly, y_train)\n",
    "    \n",
    "    # Step 5: Use the fitted LinearRegression object to predict the target variable for the test data\n",
    "    lm2_preds = lm2.predict(X_test_poly)\n",
    "    \n",
    "    # Step 6: Create a dataframe to store the actual test values and the predicted values\n",
    "    test_preds_df = pd.DataFrame({'actual_test': y_test})\n",
    "    test_preds_df['poly_test'] = lm2_preds\n",
    "    \n",
    "    # Step 7: Calculate the root mean squared error (RMSE) between the actual and predicted test values\n",
    "    poly_test_rmse = sqrt(mean_squared_error(test_preds_df.actual_test, test_preds_df['poly_test']))\n",
    "    \n",
    "    # Step 8: Return the RMSE value\n",
    "    print(f' The RMSE score on test data is: {poly_test_rmse}')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
