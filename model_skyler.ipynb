{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a68707",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "\n",
    "import sklearn.preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from prepare import remove_outliers, tts, scale_wine\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "def mod_prep():\n",
    "    white=pd.read_csv('winequality-white.csv')\n",
    "    red=pd.read_csv('winequality-red.csv')\n",
    "    red['color']= 'red'\n",
    "    white['color']= 'white'\n",
    "    wine= pd.concat([red, white], ignore_index=True)\n",
    "    wine, fences=remove_outliers(wine)\n",
    "    wine=scale_wine(wine)\n",
    "    wine=pd.get_dummies(wine, columns=['color'])\n",
    "    train, val, test= tts(wine, 'quality')\n",
    "    \n",
    "    x_train= train.drop(columns=['quality'])\n",
    "    y_train= train['quality']\n",
    "\n",
    "    x_val= val.drop(columns=['quality'])\n",
    "    y_val= val['quality']\n",
    "\n",
    "    x_test= test.drop(columns=['quality'])\n",
    "    y_test= test['quality']\n",
    "    return x_train, y_train, x_val, y_val, x_test, y_test\n",
    "\n",
    "\n",
    "def cluster_1(train):\n",
    "    train=scale_wine(train)\n",
    "    X=train[['chlorides', 'residual sugar']]\n",
    "    kmeans = KMeans(n_clusters=4)\n",
    "    kmeans.fit(X)\n",
    "    train['cluster']=kmeans.predict(X)\n",
    "    \n",
    "    centroids = pd.DataFrame(kmeans.cluster_centers_, columns=X.columns)\n",
    "\n",
    "    sns.relplot(data=train, x='chlorides', y='residual sugar', hue='cluster')\n",
    "    centroids.plot.scatter(y='residual sugar', x='chlorides', c='black', marker='x', s=1000, \n",
    "                           ax=plt.gca(), label='centroid')\n",
    "    plt.xlabel('Chlorides')\n",
    "    plt.ylabel('Residual Sugar')\n",
    "    plt.title('Residual Sugar/Chlorides Clusters')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def cluster_2(train):\n",
    "    train=scale_wine(train)\n",
    "    seed = 8675309\n",
    "    kmeans_scale = KMeans(n_clusters = 3, random_state = seed)\n",
    "    X=train[['fixed acidity', 'volatile acidity']]\n",
    "    kmeans_scale.fit(train[['fixed acidity', 'volatile acidity']])\n",
    "    \n",
    "    centroids = pd.DataFrame(kmeans_scale.cluster_centers_, columns=['fixed acidity', 'volatile acidity'])\n",
    "    \n",
    "    train['cluster']=kmeans_scale.predict(X)\n",
    "\n",
    "    sns.relplot(data = train, x = 'volatile acidity', y = 'fixed acidity', hue = 'cluster')\n",
    "    centroids.plot.scatter(y='fixed acidity', x='volatile acidity', \n",
    "                           c='black', marker='x', s=1000, ax=plt.gca(), label='centroid')\n",
    "    plt.xlabel('Volatile Acidity')\n",
    "    plt.ylabel('Fixed Acidity')\n",
    "    plt.title('Volatile Acidity/Fixed Acidity Clusters')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def baseline(train, y_train):\n",
    "    train['base']= 6\n",
    "    acc=accuracy_score(y_train,train['base'])\n",
    "    print(f'Baseline accuracy is {round(acc,2)}')\n",
    "\n",
    "\n",
    "def model(x_train, y_train, x_val, y_val, x_test, y_test):\n",
    "    metrics= []\n",
    "    rm= RandomForestClassifier(max_depth= 3, min_samples_leaf= 1, random_state=8675309)\n",
    "    rm.fit(x_train, y_train)\n",
    "    in_sample= rm.score(x_train, y_train)\n",
    "    out_of_sample= rm.score(x_val, y_val)\n",
    "    test=rm.score(x_test, y_test)\n",
    "    output={'max_depth': 3,\n",
    "            'min_samples_leaf': 1,\n",
    "            'train_accuracy': in_sample,\n",
    "            'validate_accuracy': out_of_sample,\n",
    "            'test_accuracy': test\n",
    "           }\n",
    "    metrics.append(output)\n",
    "    metrics=pd.DataFrame(data=metrics)\n",
    "    return metrics\n",
    "\n",
    "\n",
    "def model_info():\n",
    "    white=pd.read_csv('winequality-white.csv')\n",
    "    red=pd.read_csv('winequality-red.csv')\n",
    "    red['color']= 'red'\n",
    "    white['color']= 'white'\n",
    "    wine= pd.concat([red, white], ignore_index=True)\n",
    "    wine, fences=remove_outliers(wine)\n",
    "    wine=scale_wine(wine)\n",
    "    wine=pd.get_dummies(wine, columns=['color'])\n",
    "    train, val, test= tts(wine, 'quality')\n",
    "    #setting values to cluster by\n",
    "    X=train[['chlorides', 'residual sugar']]\n",
    "    V=val[['chlorides', 'residual sugar']]\n",
    "    #making, fitting, and predicting clusters\n",
    "    kmeans = KMeans(n_clusters=4, random_state=8675309)\n",
    "    kmeans.fit(X)\n",
    "\n",
    "    train['rs_chl_cluster']=kmeans.predict(X)\n",
    "    val['rs_chl_cluster']=kmeans.predict(V)\n",
    "\n",
    "    #separating into x and y\n",
    "    x_train= train.drop(columns=['quality', 'chlorides', 'residual sugar'])\n",
    "    y_train= train['quality']\n",
    "\n",
    "    x_val= val.drop(columns=['quality', 'chlorides', 'residual sugar'])\n",
    "    y_val= val['quality']\n",
    "\n",
    "    metrics= []\n",
    "\n",
    "                                                        #build the model\n",
    "    rm= RandomForestClassifier(max_depth= 2, min_samples_leaf= 1, random_state=8675309)\n",
    "                                                        #fit the model\n",
    "    rm.fit(x_train, y_train)\n",
    "                                                        #get accuracy from in and out of sample data\n",
    "    in_sample= rm.score(x_train, y_train)\n",
    "    out_of_sample= rm.score(x_val, y_val)\n",
    "                                                        #assigning the output to a dictionary\n",
    "    output={'max_depth': 2,\n",
    "            'min_samples_leaf': 1,\n",
    "            'train_accuracy': in_sample,\n",
    "            'validate_accuracy': out_of_sample,\n",
    "            'cluster': 'residual_sugar_and_chloride'\n",
    "            }\n",
    "                                                        #appending the output dictionary to the empty metrics list\n",
    "    metrics.append(output)\n",
    "\n",
    "    train=train.drop(columns=['rs_chl_cluster'])\n",
    "    val=val.drop(columns=['rs_chl_cluster'])\n",
    "    ############################################################################################\n",
    "    seed = 8675309\n",
    "    X=train[['fixed acidity', 'volatile acidity']]\n",
    "    V=val[['fixed acidity', 'volatile acidity']]\n",
    "    kmeans= KMeans(n_clusters = 3, random_state = seed)\n",
    "\n",
    "    kmeans.fit(X)\n",
    "\n",
    "    train['bart_cluster']=kmeans.predict(X)\n",
    "    val['bart_cluster']=kmeans.predict(V)\n",
    "\n",
    "    #separating into x and y\n",
    "    x_train= train.drop(columns=['quality', 'fixed acidity', 'volatile acidity'])\n",
    "    y_train= train['quality']\n",
    "\n",
    "    x_val= val.drop(columns=['quality', 'fixed acidity', 'volatile acidity'])\n",
    "    y_val= val['quality']\n",
    "\n",
    "\n",
    "                                                        #build the model\n",
    "    rm= RandomForestClassifier(max_depth= 2, min_samples_leaf= 1)\n",
    "                                                        #fit the model\n",
    "    rm.fit(x_train, y_train)\n",
    "                                                        #get accuracy from in and out of sample data\n",
    "    in_sample= rm.score(x_train, y_train)\n",
    "    out_of_sample= rm.score(x_val, y_val)\n",
    "                                                        #assigning the output to a dictionary\n",
    "    output={\n",
    "        'max_depth': 2,\n",
    "        'min_samples_leaf': 1,\n",
    "        'train_accuracy': in_sample,\n",
    "        'validate_accuracy': out_of_sample,\n",
    "        'cluster': 'fixed_acidity_and_volatile_acidity'\n",
    "    }\n",
    "                                                        #appending the output dictionary to the empty metrics list\n",
    "    metrics.append(output)\n",
    "\n",
    "    ###################################################################################\n",
    "\n",
    "    #setting values to cluster by\n",
    "    X=train[['chlorides', 'residual sugar']]\n",
    "    V=val[['chlorides', 'residual sugar']]\n",
    "    #making, fitting, and predicting clusters\n",
    "    kmeans = KMeans(n_clusters=4, random_state=8675309)\n",
    "    kmeans.fit(X)\n",
    "\n",
    "    train['rs_chl_cluster']=kmeans.predict(X)\n",
    "    val['rs_chl_cluster']=kmeans.predict(V)\n",
    "\n",
    "    #separating into x and y\n",
    "    x_train= train.drop(columns=['quality', 'fixed acidity', 'volatile acidity', 'chlorides', 'residual sugar'])\n",
    "    y_train= train['quality']\n",
    "\n",
    "    x_val= val.drop(columns=['quality', 'fixed acidity', 'volatile acidity', 'chlorides', 'residual sugar'])\n",
    "    y_val= val['quality']\n",
    "\n",
    "\n",
    "                                                        #build the model\n",
    "    rm= RandomForestClassifier(max_depth= 2, min_samples_leaf= 1, random_state=seed)\n",
    "                                                        #fit the model\n",
    "    rm.fit(x_train, y_train)\n",
    "                                                        #get accuracy from in and out of sample data\n",
    "    in_sample= rm.score(x_train, y_train)\n",
    "    out_of_sample= rm.score(x_val, y_val)\n",
    "                                                        #assigning the output to a dictionary\n",
    "    output={\n",
    "        'max_depth': 2,\n",
    "        'min_samples_leaf': 1,\n",
    "        'train_accuracy': in_sample,\n",
    "        'validate_accuracy': out_of_sample,\n",
    "        'cluster': 'both'\n",
    "    }\n",
    "                                                        #appending the output dictionary to the empty metrics list\n",
    "    metrics.append(output)\n",
    "\n",
    "    #############################################################################################\n",
    "\n",
    "    train=train.drop(columns=['rs_chl_cluster', 'bart_cluster'])\n",
    "    val=val.drop(columns=['rs_chl_cluster', 'bart_cluster'])\n",
    "\n",
    "    #separating into x and y\n",
    "    x_train= train.drop(columns=['quality'])\n",
    "    y_train= train['quality']\n",
    "\n",
    "    x_val= val.drop(columns=['quality'])\n",
    "    y_val= val['quality']\n",
    "\n",
    "                                                        #build the model\n",
    "    rm= RandomForestClassifier(max_depth= 3, min_samples_leaf= 1, random_state=8675309)\n",
    "                                                        #fit the model\n",
    "    rm.fit(x_train, y_train)\n",
    "                                                        #get accuracy from in and out of sample data\n",
    "    in_sample= rm.score(x_train, y_train)\n",
    "    out_of_sample= rm.score(x_val, y_val)\n",
    "                                                        #assigning the output to a dictionary\n",
    "    output={\n",
    "        'max_depth': 3,\n",
    "        'min_samples_leaf': 1,\n",
    "        'train_accuracy': in_sample,\n",
    "        'validate_accuracy': out_of_sample,\n",
    "        'cluster': 'none'\n",
    "    }\n",
    "                                                        #appending the output dictionary to the empty metrics list\n",
    "    metrics.append(output)\n",
    "    metrics=pd.DataFrame(data=metrics)\n",
    "    metrics['difference']=metrics['train_accuracy']-metrics['validate_accuracy']\n",
    "    return metrics\n",
    "\n",
    "\n",
    "\n",
    "def model_viz(df):\n",
    "    plt.figure(figsize=(10,7))\n",
    "    X = ['Cluster 1','Cluster 2','Both','None']\n",
    "    trainacc = df['train_accuracy']\n",
    "    valacc = df['validate_accuracy']\n",
    "    diff= df['difference']\n",
    "  \n",
    "    X_axis = np.arange(len(X))\n",
    "  \n",
    "    plt.bar(X_axis - 0.2, trainacc, 0.4, label = 'Train Accuracy', color=['blue'], ec='black')\n",
    "    plt.bar(X_axis + 0.2, valacc, 0.4, label = 'Validate Accuracy', color=['green'], ec='black')\n",
    "  \n",
    "    plt.xticks(X_axis, X)\n",
    "    plt.xlabel(\"Model Includes\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.title(\"Accuracy of Models\")\n",
    "    plt.ylim(0,.7)\n",
    "    plt.grid(True, alpha=0.3, linestyle='--')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
